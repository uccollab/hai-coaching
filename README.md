# HAI-coaching - Ask the experts: sourcing high-quality datasets for nutritional counselling through Human-AI collaboration
Official repository for HAI-coaching, the first high quality dataset for nutritional counselling, sourced through Human-AI (HAI) collaboration.

# WARNING: READ CAREFULLY
If you plan to use this dataset to prompt proprietary models (e.g. Google's Bard, OpenAI's ChatGPT etc.) always consult terms and conditions. Some companies reserve the right to keep chat logs for model improvements, which may result in data contamination which ultimately makes the dataset useless for assessing LLMs performance. If you need guidance contact the owner (Simone Balloccu) before, to avoid data leaking. For now, we know that:
- OpenAI's models are safe to prompt with this data only behind API access (NEVER feed instances from this dataset through the browser)
- Anthropic CLAUDE is never safe (the company always keeps your conversation for model training, even through API)

## Intro
> Large Language Models (LLMs), with their flexible generation abilities, can be powerful data sources in domains with few or no available corpora. However, problems like hallucinations and biases limit such applications. In this case study, we pick nutrition counselling, a domain lacking any public resource, and show that high-quality datasets can be gathered by combining LLMs, crowd-workers and nutrition experts. We first crowd-source and cluster a novel dataset of diet-related issues, then work with experts to prompt ChatGPT into producing related supportive text. Finally, we let the experts evaluate the safety of the generated text. We release HAI-coaching, the first expert-annotated nutrition counselling dataset containing ~2.4K dietary struggles from crowd workers, and ~97K related supportive texts generated by ChatGPT. Extensive analysis shows that ChatGPT while producing highly fluent and human-like text, also manifests harmful behaviours, especially in sensitive topics like mental health, making it unsuitable for unsupervised use.

Read more on how we created HAI-coaching and how it can be used in NLP in our paper: ["Ask the experts: sourcing high-quality datasets for nutritional counselling through Human-AI collaboration"
](https://arxiv.org/abs/2401.08420)

## HAI-coaching file structure
The various folder should be pretty self-explanatory and all contains their own README file. The dataset itself is in the  ``dataset.xlsx `` file and has the following structure:
* TAB "DATASET": the actual dataset, containing the following columns:
  * Columns related to the struggles and the topic they cover: 
    - `doc_no`:	Document number for that specific annotator
    - `annotator`: Which annotator (number) worked on the given struggle. If "ALL", then the struggle was used for IAA, hence annotated by everyone.	
    - `struggle`:	The struggle, after typo correction.
    - `cluster_auto`:	Coarse clustering, obtained automatically. Hyperparameters were set to capture main topics. Has been used as an aiding tool during topic modelling with experts.	
    - `cluster_expert`:	Fine-grained clustering, obtained manually in collaboration with experts. It contains more specific topics that are useful for qualitative analysis.	
    - `cluster_expert_merged`: More general clustering, where smaller topics have been merged into bigger ones.
    - `struggle_original`: The struggle as it was written by the crowdworker, before typo correction.	
    - `full_embeddings`: Embeddings for the struggle, from all-mpnet model. These can be re-calculated at any time and are present here only for quick plotting.
    - `reduced_embeddings`:	Embeddings after PCA, for 3D plotting purposes.
    			
  * Candidates from ChatGPT and their annotation. For IAA, majority voting was used. 
      - `OT`: Whether the struggle is off-topic or not	
      - `reflection_candidates`: Reflection generated by ChatGPT, divided by the "###" separator
      - `reflection_annotation`: Whether each candidate is safe or not, divided by the "###" separator
      - `reflection_from_expert`: Optional candidates written by experts, divided by the "###" separator
    
      The same structure echoes for all kind of supportive text (reframing, comfort and suggestion)

* TAB "STATS": presents some basic counts based on the clustering
* TAB "INFO": recaps dataset structure (like this README) and also shows the merging logic for clusters

  * Columns related to the demographics for each crowdworker have been removed for data privacy. We might share, at our discretion, such data with interested researchers for non-commercial purposes only.   


## Working with the dataset
The file ``dataset_parsing.ipynb`` contains (as a Jupyter notebook) some basic code to read, parse and work with the dataset.

## Other files
We also release all the relevant documents and material used in our experiments for struggles collection, clustering, prompt engineering, prompting ChatGPT and safety annotation. Each step has its own directory and README file.

## Citing this work
If you use HAI-coaching or any information from our [paper](https://arxiv.org/abs/2401.08420), please cite it as follows:
```bash
@misc{balloccu2024ask,
      title={Ask the experts: sourcing high-quality datasets for nutritional counselling through Human-AI collaboration}, 
      author={Simone Balloccu and Ehud Reiter and Vivek Kumar and Diego Reforgiato Recupero and Daniele Riboni},
      year={2024},
      eprint={2401.08420},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

